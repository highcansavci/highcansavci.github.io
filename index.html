<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can Savcı - Reinforcement Learning Researcher</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- RL Background Animation -->
    <div class="rl-background" id="rlBg"></div>

    <!-- Navigation -->
    <nav class="nav-bar">
        <div class="nav-content">
            <div class="logo">Can Savcı</div>
            <ul class="nav-links">
                <li><a href="#header">Home</a></li>
                <li><a href="#about">About</a></li>
                <li><a href="#research">Research</a></li>
                <li><a href="#skills">Skills</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Header Section -->
    <section id="header" class="header">
        <div class="hero-content">
            <img class="profile-image" src="images/image.png" alt="Can Savcı">
            <div class="rl-badge">Reinforcement Learning</div>
            <h1 class="hero-title">Can Savcı</h1>
            <p class="hero-subtitle">RL • MARL • QRL • IRL</p>
            <div class="social-links">
                <a href="https://www.linkedin.com/in/can-savci/"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/highcansavci"><i class="fab fa-github"></i></a>
                <a href="mailto:highcsavci@gmail.com"><i class="fas fa-envelope"></i></a>
            </div>
        </div>
    </section>

    <!-- About Section -->
    <section id="about" class="section fade-in">
        <h2 class="section-title">Agent Profile</h2>
        <div class="about-content">
            <div class="about-image">
                <div class="rl-diagram">
                    <svg width="300" height="300" viewBox="0 0 300 300">
                        <!-- Agent-Environment Loop -->
                        <circle cx="80" cy="150" r="30" fill="none" stroke="#ffffff" stroke-width="2"/>
                        <text x="80" y="155" text-anchor="middle" fill="#ffffff" font-size="12">Agent</text>
                        
                        <rect x="170" y="120" width="60" height="60" fill="none" stroke="#ffffff" stroke-width="2"/>
                        <text x="200" y="155" text-anchor="middle" fill="#ffffff" font-size="10">Environment</text>
                        
                        <!-- Action Arrow -->
                        <path d="M 110 140 Q 140 130 170 140" fill="none" stroke="#ffffff" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <text x="140" y="128" text-anchor="middle" fill="#cccccc" font-size="10">Action</text>
                        
                        <!-- State/Reward Arrow -->
                        <path d="M 170 160 Q 140 170 110 160" fill="none" stroke="#ffffff" stroke-width="2" marker-end="url(#arrowhead)"/>
                        <text x="140" y="182" text-anchor="middle" fill="#cccccc" font-size="10">State, Reward</text>
                        
                        <!-- Arrow marker definition -->
                        <defs>
                            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#ffffff"/>
                            </marker>
                        </defs>
                    </svg>
                </div>
            </div>
            <div class="about-text">
                <p>I am pleased to introduce myself as <strong>Can Savcı</strong>, an aspiring scholar and technologist specializing in the intersection of <strong>Reinforcement Learning</strong> and <strong>Quantum Computing</strong>. My academic journey commenced with securing the <strong>1417th position in the YGS/LYS Exam</strong>, leading to my admission into <strong>Bilkent University</strong> with a Comprehensive Scholarship.</p>
                
                <p>My research focuses on developing <strong>intelligent agents</strong> that can learn optimal policies through interaction with complex environments. I am particularly fascinated by the <strong>Markov Decision Process</strong> framework and its applications in real-world scenarios where uncertainty and partial observability present significant challenges.</p>

                <p>I am also fascinated by <strong>exploration strategies</strong> that can learn optimality through interaction with complex environments and <strong>credit assignment problem</strong> which is the fundamental bottleneck in MARL area.</p>

                <p>My current work bridges classical reinforcement learning with <strong>quantum-enhanced algorithms</strong>, exploring how quantum superposition and entanglement can improve exploration strategies and policy convergence in multi-agent systems. Through rigorous mathematical formulation and experimental validation, I aim to push the boundaries of what's possible in autonomous decision-making systems.</p>
            </div>
        </div>

        <div class="rl-areas">
            <div class="rl-card">
                <div class="rl-icon marl"><i class="fas fa-project-diagram"></i></div>
                <h3>Multi-Agent RL (MARL)</h3>
                <p>Developing coordination strategies for multiple agents in shared environments, focusing on Nash equilibria and cooperative policy learning with communication protocols.</p>
            </div>
            <div class="rl-card">
                <div class="rl-icon irl"><i class="fas fa-search-plus"></i></div>
                <h3>Inverse RL (IRL)</h3>
                <p>Inferring reward functions from expert demonstrations using maximum entropy methods and Bayesian approaches to understand implicit objectives.</p>
            </div>
            <div class="rl-card">
                <div class="rl-icon explainable"><i class="fas fa-eye"></i></div>
                <h3>Explainable RL</h3>
                <p>Making agent decision-making transparent through attention mechanisms, saliency maps, and interpretable policy representations for human-AI collaboration.</p>
            </div>
            <div class="rl-card">
                <div class="rl-icon robust"><i class="fas fa-shield-alt"></i></div>
                <h3>Robust RL</h3>
                <p>Ensuring reliable performance under distributional shift, adversarial perturbations, and environmental uncertainty through risk-aware optimization.</p>
            </div>
            <div class="rl-card">
                <div class="rl-icon quantum"><i class="fas fa-atom"></i></div>
                <h3>Quantum RL (QRL)</h3>
                <p>Leveraging quantum superposition and entanglement to enhance exploration, accelerate convergence, and solve exponentially complex state spaces.</p>
            </div>
        </div>
    </section>

    <!-- Research Section -->
    <section id="research" class="section fade-in">
        <h2 class="section-title">Featured Research</h2>
        <div class="research-highlight">
            <h3 class="research-title">COMA++: Quantum-Enhanced Communication in Multi-Agent Reinforcement Learning for Marine Debris Collection Optimization</h3>
            <p class="research-authors">Can Savcı, Tansel Akgül, Berkant Bıçakçı</p>
            <p class="research-conference">10. Uluslararası Bilgisayar Bilimleri ve Mühendisliği Konferansı (UBMK 2025)</p>
            
            <p><strong>Abstract:</strong> This research advances multi-agent systems for marine plastic and solid waste collection through a novel quantum-enhanced reinforcement learning framework. We developed a hybrid architecture featuring <strong>GRU-based actors</strong> and <strong>attention-mechanism critics</strong>, systematically addressing the fundamental challenges of partial observability, insufficient exploration, and policy collapse in traditional MARL methods.</p>
            
            <p><strong>Key Innovation:</strong> The integration of <strong>quantum circuits</strong> with MARL enables unprecedented exploration capacity beyond classical RL limitations. Our quantum-enhanced structure achieves more stable policy learning while enabling discovery of strategies unreachable by classical methods, demonstrating measurable improvements in coordination efficiency and environmental impact reduction.</p>
            
            <p><strong>Impact:</strong> COMA++ represents a significant contribution to both the academic understanding of quantum-classical hybrid learning systems and practical environmental sustainability applications, providing a scalable framework for autonomous marine cleanup operations.</p>
        </div>
    </section>

    <!-- Skills Section -->
    <section id="skills" class="section fade-in">
        <h2 class="section-title">Technical Proficiencies</h2>
        <div class="skills-grid">
            <div class="skill-item">
                <div class="skill-name">
                    <span>RL</span>
                    <span class="skill-percentage">95%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.1s; width: 95%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>IRL</span>
                    <span class="skill-percentage">90%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.2s; width: 90%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Multi-Agent RL</span>
                    <span class="skill-percentage">85%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.3s; width: 85%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Quantum RL</span>
                    <span class="skill-percentage">75%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.4s; width: 75%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Neural Network Architectures</span>
                    <span class="skill-percentage">88%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.5s; width: 88%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Python & PyTorch</span>
                    <span class="skill-percentage">92%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.6s; width: 92%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Mathematical Optimization</span>
                    <span class="skill-percentage">80%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.7s; width: 80%"></div>
                </div>
            </div>
            <div class="skill-item">
                <div class="skill-name">
                    <span>Computer Vision</span>
                    <span class="skill-percentage">85%</span>
                </div>
                <div class="skill-bar">
                    <div class="skill-progress" style="animation-delay: 0.8s; width: 85%"></div>
                </div>
            </div>
        </div>
    </section>

    <!-- Experience Section -->
    <section id="experience" class="section fade-in">
        <h2 class="section-title">Professional Experience</h2>
        <div class="timeline">
            <div class="timeline-item">
                <div class="timeline-node"></div>
                <div class="timeline-content">
                    <div class="timeline-date">Aug 2023 - Mar 2024</div>
                    <h3 class="timeline-title">Computer Vision Engineer</h3>
                    <div class="timeline-company">ArVis Technology</div>
                    <p class="timeline-description">Developed advanced computer vision architectures including ResNet, UNet, YOLO, GAN and VAE for complex image processing tasks. Applied both traditional and modern CV techniques to solve localization, cleaning, comparison, colorization, and face swapping challenges.</p>
                </div>
            </div>
            <div class="timeline-item">
                <div class="timeline-node"></div>
                <div class="timeline-content">
                    <div class="timeline-date">Nov 2022 - May 2023</div>
                    <h3 class="timeline-title">Machine Learning Engineer</h3>
                    <div class="timeline-company">SemperTech</div>
                    <p class="timeline-description">Implemented state-of-the-art Intent Detection and Slot Filling models using BERT and GPT2. Optimized deployment on Jetson TX2 using OnnxRuntime, PyTorch and TensorRT. Managed end-to-end ML pipeline from data creation to model deployment.</p>
                </div>
            </div>
            <div class="timeline-item">
                <div class="timeline-node"></div>
                <div class="timeline-content">
                    <div class="timeline-date">Jun 2021 - Nov 2022</div>
                    <h3 class="timeline-title">Junior Software Engineer</h3>
                    <div class="timeline-company">AYESAŞ</div>
                    <p class="timeline-description">Developed mission-critical defense systems using Java 8, OSGi, and Swing frameworks. Mastered advanced software engineering practices including clean code principles, design patterns, and multithreading optimization.</p>
                </div>
            </div>
            <div class="timeline-item">
                <div class="timeline-node"></div>
                <div class="timeline-content">
                    <div class="timeline-date">Jun 2020 - Aug 2020</div>
                    <h3 class="timeline-title">Blockchain Research Intern</h3>
                    <div class="timeline-company">TUBU ARGE</div>
                    <p class="timeline-description">Developed smart contracts in Solidity and implemented Blockchain-as-a-Service APIs. Conducted research on Elliptic Curve Diffie-Hellman protocols and delivered technical presentations on cryptographic implementations.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="section fade-in">
        <h2 class="section-title">Initiate Communication Protocol</h2>
        <div class="contact-grid">
            <div class="contact-item">
                <i class="fas fa-phone"></i>
                <h3>Direct Line</h3>
                <p>+905307801024</p>
            </div>
            <div class="contact-item">
                <i class="fas fa-envelope"></i>
                <h3>Electronic Mail</h3>
                <p>highcsavci@gmail.com</p>
            </div>
            <div class="contact-item">
                <i class="fab fa-linkedin"></i>
                <h3>Professional Network</h3>
                <p>Connect for collaborations</p>
            </div>
            <div class="contact-item">
                <i class="fab fa-github"></i>
                <h3>Code Repository</h3>
                <p>Explore implementations</p>
            </div>
        </div>
        <div class="action-buttons">
            <a href="mailto:highcsavci@gmail.com" class="btn">
                <i class="fas fa-paper-plane"></i>
                <span>Collaborate</span>
            </a>
            <a href="images/can_savci_030424.pdf" class="btn">
                <i class="fas fa-file-download"></i>
                <span>Download CV</span>
            </a>
        </div>
    </section>

    <script>
        // RL-specific Background Animation
        function createRLBackground() {
            const container = document.getElementById('rlBg');
            
            // Create agent nodes
            for (let i = 0; i < 8; i++) {
                const agent = document.createElement('div');
                agent.className = 'agent-node';
                agent.style.left = Math.random() * 90 + '%';
                agent.style.top = Math.random() * 90 + '%';
                agent.style.animationDelay = Math.random() * 4 + 's';
                container.appendChild(agent);
            }

            // Create environment grid
            for (let i = 0; i < 20; i++) {
                const grid = document.createElement('div');
                grid.className = 'environment-grid';
                grid.style.left = Math.random() * 95 + '%';
                grid.style.top = Math.random() * 95 + '%';
                grid.style.width = '30px';
                grid.style.height = '30px';
                container.appendChild(grid);
            }

            // Create reward signals
            for (let i = 0; i < 15; i++) {
                const reward = document.createElement('div');
                reward.className = 'reward-signal';
                reward.style.left = Math.random() * 98 + '%';
                reward.style.top = Math.random() * 98 + '%';
                reward.style.animationDelay = Math.random() * 2 + 's';
                container.appendChild(reward);
            }

            // Add mathematical symbols
            const symbols = ['γ', 'α', 'ε', 'π', 'Q*', 'V(s)', '∇', 'θ', 'λ', 'τ'];
            symbols.forEach((symbol, index) => {
                const mathElement = document.createElement('div');
                mathElement.className = 'math-symbols';
                mathElement.textContent = symbol;
                mathElement.style.left = Math.random() * 90 + '%';
                mathElement.style.top = Math.random() * 90 + '%';
                mathElement.style.animationDelay = index * 0.5 + 's';
                container.appendChild(mathElement);
            });
        }

        // Scroll animations
        function handleScrollAnimations() {
            const elements = document.querySelectorAll('.fade-in');
            elements.forEach(element => {
                const elementTop = element.getBoundingClientRect().top;
                const elementVisible = 150;
                
                if (elementTop < window.innerHeight - elementVisible) {
                    element.classList.add('visible');
                }
            });
        }

        // Smooth scrolling for navigation
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Navigation background opacity on scroll
        window.addEventListener('scroll', () => {
            const navbar = document.querySelector('.nav-bar');
            if (window.scrollY > 50) {
                navbar.style.background = 'rgba(0, 0, 0, 0.98)';
            } else {
                navbar.style.background = 'rgba(0, 0, 0, 0.95)';
            }
            handleScrollAnimations();
        });

        // Initialize everything when page loads
        document.addEventListener('DOMContentLoaded', function() {
            createRLBackground();
            handleScrollAnimations();
            
            // Add click effects to buttons
            document.querySelectorAll('.btn').forEach(btn => {
                btn.addEventListener('click', function(e) {
                    const ripple = document.createElement('span');
                    ripple.style.position = 'absolute';
                    ripple.style.borderRadius = '50%';
                    ripple.style.background = 'rgba(255, 255, 255, 0.6)';
                    ripple.style.transform = 'scale(0)';
                    ripple.style.animation = 'ripple 0.6s linear';
                    ripple.style.left = (e.clientX - e.target.offsetLeft) + 'px';
                    ripple.style.top = (e.clientY - e.target.offsetTop) + 'px';
                    this.appendChild(ripple);
                    
                    setTimeout(() => {
                        ripple.remove();
                    }, 600);
                });
            });
        });

        // Add ripple animation
        const style = document.createElement('style');
        style.textContent = `
            @keyframes ripple {
                to {
                    transform: scale(4);
                    opacity: 0;
                }
            }
        `;
        document.head.appendChild(style);
    </script>
</body>
</html>




